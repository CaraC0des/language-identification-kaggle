{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4df0851",
   "metadata": {},
   "source": [
    "# Language Identification in South African Text: Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b468bf",
   "metadata": {},
   "source": [
    "This notebook presents my approach to tackle the Language Identification Challenge on Kaggle. The challenge focuses on classifying text written in South Africa's 11 Official languages. The notebook covers data exploration, preprocessing, feature extraction, model training, evaluation, and submission generation. By leveraging machine learning techniques, I aim to develop a classification model that accurately predicts the language of a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126473eb",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ddd8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6ab6e",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d12a846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_set.csv')\n",
    "test_df = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf479c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d85b16a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset:\n",
      "  lang_id                                               text\n",
      "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
      "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
      "2     eng  the province of kwazulu-natal department of tr...\n",
      "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
      "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
      "\n",
      "Test Dataset:\n",
      "   index                                               text\n",
      "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
      "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
      "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
      "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
      "4      5                      Winste op buitelandse valuta.\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Dataset:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTest Dataset:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc9919",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b9b6e4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(train_df, test_df):\n",
    "    # Initializing the TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Fitting the vectorizer on the training data\n",
    "    vectorizer.fit(train_df['text'])\n",
    "\n",
    "    # Transforming the training and test data using the fitted vectorizer\n",
    "    train_features = vectorizer.transform(train_df['text'])\n",
    "    test_features = vectorizer.transform(test_df['text'])\n",
    "\n",
    "    return train_features, test_features, vectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cc091",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4890d372",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, vectorizer = preprocess_data(train_df, test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48ae62",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271efad4",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f41f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1 Score: 0.994245605433102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cara\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_features, train_df['lang_id'], test_size=0.2, random_state=42)\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_preds = lr_model.predict(X_val)\n",
    "lr_f1 = f1_score(y_val, lr_preds, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression F1 Score:\", lr_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152e48bd",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aa8cd9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN F1 Score: 0.9593450685034197\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_preds = knn_model.predict(X_val)\n",
    "knn_f1 = f1_score(y_val, knn_preds, average='weighted')\n",
    "\n",
    "print(\"KNN F1 Score:\", knn_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f80e7",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f4a3052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM F1 Score: 0.9942650475719715\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_predictions = svm.predict(X_val)\n",
    "svm_f1 = f1_score(y_val, svm_predictions, average='weighted')\n",
    "print(\"SVM F1 Score:\", svm_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d8030e",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8ddb7f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes F1 Score: 0.9980299054262277\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_predictions = nb.predict(X_val)\n",
    "nb_f1 = f1_score(y_val, nb_predictions, average='weighted')\n",
    "print(\"Naive Bayes F1 Score:\", nb_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e4828",
   "metadata": {},
   "source": [
    "## Generate predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57d6636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the test data into TF-IDF vectors\n",
    "X_test = vectorizer.transform(test_data['text'])\n",
    "\n",
    "# Generating predictions on the best performing model\n",
    "test_predictions = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8dee2",
   "metadata": {},
   "source": [
    "## Creating a csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da552c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a submission dataframe with 'index' and 'lang_id' columns\n",
    "submission_df = pd.DataFrame({'index': test_data['index'], 'lang_id': test_predictions})\n",
    "\n",
    "submission_df.to_csv('FinalSub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41dd6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4c9c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
